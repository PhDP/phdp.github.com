<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Philippe Desjardins-Proulx -- Posts</title>
    <link href="http://phdp.github.io//atom.xml" rel="self" />
    <link href="http://phdp.github.io/" />
    <id>http://phdp.github.io//atom.xml</id>
    <author>
        <name>Philippe Desjardins-Proulx</name>
        <email>philippe.d.proulx@gmail.com</email>
    </author>
    <updated>2015-07-13T00:00:00Z</updated>
    <entry>
    <title>A gentle introduction to statistical relational learning: maths, code, and examples</title>
    <link href="http://phdp.github.io//posts/2015-07-13-srl-code.html" />
    <id>http://phdp.github.io//posts/2015-07-13-srl-code.html</id>
    <published>2015-07-13T00:00:00Z</published>
    <updated>2015-07-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>A gentle introduction to statistical relational learning: maths, code, and examples</h1>
<a href="https://twitter.com/share" class="twitter-share-button" data-text="A gentle introduction to statistical relational learning: maths, code, and examples" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>2015.07.13</p>
<p>Statistical relational learning is a branch of machine learning (A.I.)
devoted to unify probability theory and logic. I'll write another post later
to explain the motivation and a bit of history of this fascinating branch of
study, but here I want to focus on a concrete example, with detailed
maths and code.</p>

<p>The approach to statistical relational learning explained here is called
Markov logic network (MLN), <a
href='https://homes.cs.washington.edu/~pedrod/kbmn.pdf'>discovered in 2006 by
Richardson and Domingos.</a> Their paper has a nice simple example of MLN
applied to the relationship between smoking and cancer. However, it's a bit
hard to follow unless you're used to read papers on both logic and
probabilistic graphical models.  In this post, I will mostly follow their
smoking/cancer example, but I will try to be much more explicit. I'll also do a
demonstration with <a href='https://github.com/PhDP/Sphinx-AI'>Sphinx-AI</a>, a
small implementation I wrote for playing with statistical relational models.</p>

<p>A Markov logic network is simply a set of formulas written in first-order
logic, each associated with a weight. We'll use this for our examples:</p>

<table style='width: 80%'>
  <tr>
    <th>Statement</th>
    <th>Weight</th>
  </tr>
  <tr>
    <td>Smoking causes cancers</td>
    <td align='center'>1.5</td>
  </tr>
  <tr>
    <td>If two people are friends and one smokes, then so does the other</td>
    <td align='center'>1.1</td>
  </tr>
</table>

<p>Using a more formal representation, with the weight following the
first-order logic formula, we get:</p>

\[\forall x: Smoking(x) \Rightarrow Cancer(x), 1.5;\]
\[\forall x, y: Friend(x, y) \land Smoking(x) \Rightarrow Smoking(y), 1.1;\]

<p>And that's our Markov logic network. If you don't know much about
first-order logic, <a href='2015-07-13-fol.html'>I wrote a short introduction
here that is more than enough to understand Markov logic networks</a>.</p>

<p>The grand idea of statistical relational learning is that, in pure logic, a
world is false if it violates a single formula, but with Markov logic networks,
a world is <i>less likely</i> if it violates formulas, especially if it
violates formula with a high weight. Statistical relational learning has
important advantages on probabilistic approaches: a first-order logic formula
is simple to understand and interpret, plus it can be manipulated by humans and
computers in ways a naked probabilistic model can't. I think the greatest
advantage of Markov logic networks, and statistical relational approaches in
general, is to go beyond data models to form a general knowledge base. Just
like old expert systems, but without the inflexibility of logic.</p>

<p>But enough with the background, let's look at an example.</p>

<h2>From Markov logic networks to inference in Markov networks</h2>

<p>The first odd with Markov logic networks, is that there's no network. All we
got is a set of weighted first-order logic formulas. A Markov logic network can
be seen as a template for Markov networks. That is: there is no network in the
Markov logic network, but we'll use it to generate networks. Take the formula:</p>

\[\forall x: Smoking(x) \Rightarrow Cancer(x), 1.5;\]

<p><i>x</i> is a variable, and to get a concrete model for inference from this
template, we need to apply constants (real objects) to the MLN so we can
replace these variables. So in essence:</p>

\[\mbox{MLN (weighted formulas) + Constants} \rightarrow \mbox{Markov Network}\]

<p>If you're confused, don't worry, it'll become clear with examples. Let's say
we are interested in the relationship between smoking/cancer/friendship for
three constants: Jerry, Elaine, George. We can apply these constants to the
formula to get a set of ground formulas.  The term <i>ground</i> means the
variables are replaced by constants, that is, concrete objects. For example in
mathematics you probably encountered first-order logic formulas like:</p>

\[\forall x: Add(x, 0) = x.\]

<p>We can ground this first-order logic formula by replacing <i>x</i> with an
actual integer:</p>

\[Add(47, 0) = 47.\]
\[Add(1729, 0) = 1729.\]

<p>Similarly, applying the set of constants \(\{Elaine, Jerry, George\}\) to
our first formula yields a set of ground formulas:</p>

\[Smoking(Elaine) \Rightarrow Cancer(Elaine), 1.5;\]
\[Smoking(Jerry) \Rightarrow Cancer(Jerry), 1.5;\]
\[Smoking(George) \Rightarrow Cancer(George), 1.5;\]

<p>We could do the same thing with the other formula, which has two variables:</p>

\[Friend(Elaine, Elaine) \land Smoking(Elaine) \Rightarrow Smoking(Elaine), 1.1;\]
\[Friend(Elaine, Jerry) \land Smoking(Elaine) \Rightarrow Smoking(Jerry), 1.1;\]
\[Friend(Elaine, George) \land Smoking(Elaine) \Rightarrow Smoking(George), 1.1;\]
\[Friend(Jerry, Elaine) \land Smoking(Jerry) \Rightarrow Smoking(Elaine), 1.1;\]
\[Friend(Jerry, Jerry) \land Smoking(Jerry) \Rightarrow Smoking(Jerry), 1.1;\]
\[Friend(Jerry, George) \land Smoking(Jerry) \Rightarrow Smoking(George), 1.1;\]
\[Friend(George, Elaine) \land Smoking(George) \Rightarrow Smoking(Elaine), 1.1;\]
\[Friend(George, Jerry) \land Smoking(George) \Rightarrow Smoking(Jerry), 1.1;\]
\[Friend(George, George) \land Smoking(George) \Rightarrow Smoking(George), 1.1;\]

<p>We'll get our network from these ground formulas. From the groundings of the
two formulas, we get a set of predicates:</p>

\[\{Smoking(Elaine), Smoking(Jerry), Smoking(George), Cancer(Elaine),\]

\[Cancer(Jerry), Cancer(George), Friend(Elaine, Elaine), Friend(Elaine, Jerry),\]

\[Friend(Elaine, George), Friend(Jerry, Elaine), Friend(Jerry, Jerry),\]

\[Friend(Jerry, George), Friend(George, Elaine),\]

\[Friend(George, Jerry), Friend(Jerry, George)\}\]

<p>Markov logic networks provide the structure to answer question of the type</p>

\[P(Cancer(George) \mid Smoking(Jerry), Friend(Jerry, George)),\]

<p>where our variables (in the probabilistic sense) are the ground predicates.
Of course, we could generate a completely different set of ground formulas and
ground predicates if we apply, say, the constants \(\{William, Anastasia,
Kara, Saul, Karl, Tory, Felix, Laura\}\), or any number of objects we're
interested in.</p>

<p>To finally see the network and answer probabilistic queries, we'll create
one node for each ground predicate, and link all nodes that are in the same
ground formula. In our example with the constants \(\{Elaine, Jerry, George\}\), we
get the following Markov network:</p>

<div class="imagecenter">
  <img src="../images/ground_seinfeld.png" alt="ground network"/>
</div>

<p>That said, to make it easier to follow, we'll generate a simpler network by
applying only two constants to the same two formulas: \(\{Kara, Lee\}\). We
get:</p>

<div class="imagecenter">
  <img src="../images/mln_kara_lee.png" alt="Kara Lee network"/>
</div>

<p>To understand how to query the network, it's easier to focus on the factor
graph. In the factor graph, there is a factor for all ground formulas, and all
the ground predicates found in the ground formula are linked to the factor:</p>

<div class="imagecenter">
  <img src="../images/mln_kara_lee_factors.png" alt="Kara Lee network"/>
</div>

<p>By applying \(\{Kara, Lee\}\) to our two formulas we got the ground formulas
</p>

\[Smoking(Kara) \Rightarrow Cancer(Kara), 1.5;\]
\[Smoking(Lee) \Rightarrow Cancer(Lee), 1.5;\]
\[Friend(Kara, Kara) \land Smoking(Kara) \Rightarrow Smoking(Kara), 1.1;\]
\[Friend(Kara, Lee) \land Smoking(Kara) \Rightarrow Smoking(Lee), 1.1;\]
\[Friend(Lee, Kara) \land Smoking(Lee) \Rightarrow Smoking(Kara), 1.1;\]
\[Friend(Lee, Lee) \land Smoking(Lee) \Rightarrow Smoking(Lee), 1.1;\]

<p>And you can see all the six ground formulas have a corresponding factor (the
squares) in the graph. From there, if we want to compute \(P(X = x)\), we use
the equation</p>

\[P(X = x) = \frac{1}{Z}\exp\left(\sum_i w_ig_i(x) \right),\]

<p>where \(w_i\) is the weight of the formula associated with the <i>i</i>th
factor, \(g_i\) equals 1 if the formula is true given the values of the
predicates or 0 if it's false, and \(Z\) is a normalizing constant, that is:
it's the sum of the values of all possible assignments:</p>

\[Z = \sum_{x' \in \ \mathcal{X}}\exp\left(\sum_i w_ig_i(x') \right),\]

<p>with \(\mathcal{X}\) being the set of possible assignments. Now, let's try
to compute the probability of Kara and Lee being mutual friend, neither of them
being friend with themselves, Kara smokes and has cancer, but Lee neither
smokes nor has cancer. We'll get the following network (green = true
predicates, red = false predicates):</p>

<div class="imagecenter">
  <img src="../images/mln_kara_lee_factors_ass_p1.png" alt="Kara Lee network"/>
</div>

<p>The value of the predicates can then be used to determine the factors that
are true (worth 1, in green) and those that are false (worth 0, in red):</p>

<div class="imagecenter">
  <img src="../images/mln_kara_lee_factors_ass_p2.png" alt="Kara Lee network"/>
</div>

<p>If you are confused about how factors are resolved, it's probably because
you misinterpret the logic symbol implies \(\Rightarrow\),
<a href='2015-07-13-fol.html'>check here for clarifications</a>. For example,
the factor for \(Smoking(Lee) \Rightarrow Cancer(Lee)\) is true, because
\(False \Rightarrow x\) returns true regardless of whether <i>x</i> is true or
false.</p>

<p>With the factors resolved, we can compute the probability:</p>

\[\frac{1}{Z}\exp\left(1 \times 1.1 + 1 \times 1.1 + 1 \times 1.1 + 0 \times 1.1 + 1 \times 1.5 + 1 \times 1.5\right),\]
\[\frac{1}{Z}\exp\left(3 \times 1.1 + 2 \times 1.5\right),\]
\[\frac{544.57}{Z}.\]

<p>The normalizing constant is \(Z = 229210.5024\), so our probability
is:</p>

\[\frac{544.57}{229210.5024} = 0.0023759.\]

<p>If we were to flip Cancer(Kara) to false, we'd get a lower probability (because smoking causes cancer):</p>

\[\frac{1}{Z}\exp\left(3 \times 1.1 + 1 \times 1.5\right) = \frac{121.51}{229210.5024} = 0.00053012.\]

<h2>Code Example</h2>

<p>In this section we'll perform an exact inference on a few MLNs. If you want
to follow the examples, you can copy the library with:</p>

<div class='terminal'><pre>
$ git clone https://github.com/PhDP/Sphinx-AI.git
$ cd Sphinx-AI
$ cabal install
</pre></div>

<p>The code is tested on both Linux and Windows, and it should work fine on OSX
with the <a href='https://www.haskell.org/platform/'>Haskell platform
installed</a>. Right now, it performs only exact inference, which is useful for
tests...  but it does not scale since the Markov networks generated by Markov
logic are humongous even with a few constants. Hopefully there are many good
algorithms for inference, but for now they are not sufficiently tested in
Sphinx. Anyway, exact inference will be enough for exploring a few
models.</p>

<p>First, we launch an interactive console from the root of the code:</p>

<div class='terminal'><pre>
$ cabal repl
</pre></div>

<p>Then, we'll load the Markov logic network module:</p>

<pre><code class="haskell">ghci> import Sphinx.MarkovLogic</code></pre>

<p>The most straightforward way to build a Markov logic network is with
<i>fromStrings</i>. This function takes an array of strings, each of which must
be a valid first-order logic formula followed (or preceded) by a number (the
weight of the formula). In our smoking example we have:</p>

<pre><code class="haskell">ghci> let mln = fromStrings ["∀x Smoking(x) ⇒ Cancer(x) 1.5", "∀x∀y Friend(x, y) ∧ Smoking(x) ⇒ Smoking(y) 1.1"]</code></pre>

<p>The strings were copy-pasted from Richardson and Domingos' paper, but the
parsers is flexible and will accept a keyboard-friendly form too:</p>

<pre><code class="haskell">ghci> fromStrings ["1.5 forall x Smoking(x) implies Cancer(x)", "1.1 forall x, y Friend(x, y) and Smoking(x) implies Smoking(y)"]</code></pre>

<p>We can use <i>fmtMLN</i> function to print the Markov logic
network:</p>

<pre><code class="haskell">ghci> putStrLn (fmtMLN mln)
1.5                     ∀x Smoking(x) ⇒ Cancer(x)
1.1                     ∀x ∀y Friend(x, y) ∧ Smoking(x) ⇒ Smoking(y)</code></pre>

<p>Since a Markov logic network is a template for Markov networks. To get a
Markov network, we need to apply a set of constant to the Markov logic networks
Following our example in the last section we'll use:</p>

<pre><code class="haskell">ghci> let cs = ["Elaine", "George", "Jerry"]</code></pre>

<p>Then, we can query the network, say, what is the probability that Jerry has
cancer?</p>

<pre><code class="haskell">ghci> ask mln cs "P(Cancer(Jerry))"
Just 0.6040175344121184</code></pre>

<p>The function <i>ask</i> takes a Markov logic network, a list
of terms (represented as a list of strings), and a string query. It will return
Just P, with P being a probability in the [0.0, 1.0] range, or Nothing if the
parser fails to read the query. To make the process a bit easier we'll create
a function <i>query</i> with the first two arguments supplied so we don't need to
repeat them ad nauseam:</p>

<pre><code class="haskell">ghci> let query = ask mln cs</code></pre>

<p>Then we can ask queries with this function:</p>

<pre><code class="haskell">ghci> query "P(Cancer(Jerry), Cancer(Elaine))"
Just 0.3696834237837972
ghci> query "P(Cancer(Jerry) | Smoking(Jerry))"
Just 0.8175744761936782
</code></pre>

<p>While the formulas look distinct in the Markov logic network, the fact that
they share predicates link them. So, even if there is no direct relationship
between friendship and cancer, we have:</p>

<pre><code class="haskell">ghci> query "P(Cancer(Jerry) | Smoking(Elaine))"
Just 0.6506081590969498
ghci> query "P(Cancer(Jerry) | Smoking(Elaine), Friend(Elaine, Jerry))"
Just 0.7043948532279771
</code></pre>

<p>...just as expected, because friends tend to smoke, so Elaine being Jerry's
friend increases the chance that Jerry is smoking, and if we know he doesn't
we'll get:</p>

<pre><code class="haskell">ghci> query "P(Cancer(Jerry) | Smoking(Elaine), Friend(Elaine, Jerry), !Smoking(Jerry))"
Just 0.4999999999999964
ghci> query "P(Cancer(Jerry) | !Smoking(Jerry))"
Just 0.5000000000000238
</code></pre>

<p>The cool thing with all of this is that we already have a rich structure for
inference from just two simple logical formulas, weights, and a list of objects
to ground the formulas.</p>

<p>We can add a logic formula to the network with the <i>tell</i> function. It
takes a string (just like <i>fromStrings</i> takes a list of strings), an
existing Markov logic network, and will return a new Markov logic network with
the formula added. Let's say we want to add a rule that <i>friends of friends are
friends</i>, we could add this rule with a weight of 2.0 with:</p>

<pre><code class="haskell">ghci> let mln' = tell "2.0 A.x,y,z Friend(x, y) and Friend(y, z) => Friend(x, z)" mln
ghci> putStrLn (fmtMLN mln')
1.5                     ∀x Smoking(x) ⇒ Cancer(x)
2.0                     ∀x ∀y ∀z Friend(x, y) ∧ Friend(y, z) ⇒ Friend(x, z)
1.1                     ∀x ∀y Friend(x, y) ∧ Smoking(x) ⇒ Smoking(y)</code></pre>

<p>We'll build an ask function for this network using the same constants
(Jerry, Elaine, George):</p>

<pre><code class="haskell">ghci> let query' = ask mln' cs</code></pre>

<p>Let's compare how our first MLN behaved compare to our new one:</p>

<pre><code class="haskell">ghci> query "P(Smoking(George) | Smoking(Jerry), Friend(Jerry, Elaine), Friend(Elaine, George))"
Just 0.5877406718485353
ghci> query' "P(Smoking(George) | Smoking(Jerry), Friend(Jerry, Elaine), Friend(Elaine, George))"
Just 0.7080082227672424
</code></pre>

<p>Same query, same information, but with a different model (the MLN), we get
different answers. Now, something is bugging me with the original model:</p>

<pre><code class="haskell">ghci> query "P(Cancer(Jerry) | Smoking(George))"
Just 0.6506081590969498
ghci> query "P(Cancer(Jerry) | Smoking(George), Friend(George, Jerry))"
Just 0.7043948532279771
ghci> query "P(Cancer(Jerry) | Smoking(George), Friend(Jerry, George))"
Just 0.6506081590968945
</code></pre>

<p>The problem is that friendship is assymmetricial in this MLN.  If we know
George is friend with Jerry, there's a very good chance that Jerry is friend
with George, and thus influenced by his smoking habit. The nice thing with
Markov logic is that all formulas are connected, so we can fix this issue by
adding a formula, our new Markov logic network is:</p>

\[\forall x: Smoking(x) \Rightarrow Cancer(x), 1.5;\]
\[\forall x, y: Friend(x, y) \land Smoking(x) \Rightarrow Smoking(y), 1.1;\]
\[\forall x, y: Friend(x, y) \iff Friend(y, x), 2.0;\]

<p>The last formula has the \(\iff\) operator, which is true either when both
sides are true, or when both sides are false. Thus, this formula says: if \(x\)
is friend with \(y\), then \(y\) is friend with \(x\), and if \(x\) is not friend
with \(y\), then \(y\) is not friend with \(x\). Since it's probabilistic, it doesn't
need to be true all the time, but I give it a fairly high weight. And now we have:</p>

<pre><code class="haskell">ghci> let mln'' = tell "ForAll x, y: Friend(x, y) iff Friend(y, x) 2.0" mln
ghci> putStrLn (fmtMLN mln'')
1.5                     ∀x Smoking(x) ⇒ Cancer(x)
1.1                     ∀x ∀y Friend(x, y) ∧ Smoking(x) ⇒ Smoking(y)
2.0                     ∀x ∀y Friend(x, y) ⇔ Friend(y, x)
ghci> let query'' = ask mln'' cs
ghci> query'' "P(Cancer(Jerry) | Smoking(George))"
Just 0.6506081590969105
ghci> query'' "P(Cancer(Jerry) | Smoking(George), Friend(George, Jerry))"
Just 0.7043948532279295
ghci> query'' "P(Cancer(Jerry) | Smoking(George), Friend(Jerry, George))"
Just 0.7018023327893508
</code></pre>

<p>Again, with the same information, the same query, just by adding a simple
formula we were able to get a richer model. Of course, there's much more to
Markov logic networks than simple inference, we can learn new formulas from
data, combine existing knowledge bases, transfer knowledge between domains...</p>


]]></summary>
</entry>
<entry>
    <title>A crash course in first-order logic</title>
    <link href="http://phdp.github.io//posts/2015-07-13-fol.html" />
    <id>http://phdp.github.io//posts/2015-07-13-fol.html</id>
    <published>2015-07-13T00:00:00Z</published>
    <updated>2015-07-13T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>A crash course in first-order logic</h1>
<a href="https://twitter.com/share" class="twitter-share-button" data-text="A crash course in first-order logic" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>2015.07.13</p>
<p>This is a short but complete description of first-order logic, a rich system
to reason about objects and their relationships. I care mostly about
first-order logic for its role in statistical relational learning (a branch of
machine learning), <a href='2015-07-13-srl-code.html'>which I'll cover in
another post</a>. Here, I just describe logic. If you want a more detailed
explanation, see <a href='http://aima.cs.berkeley.edu/'>Russell and Norvig's
excellent A.I.  book.</a></p>

<h2>Terms</h2>

<p>Terms represent objects and relationships between objects, they are the
reason why logic is so flexible. There are three types of terms:</p>

<ol type='I'>
  <li><b>Constants</b> represent objects, e.g.: <i>Tokyo</i>, the number <i>47</i>, <i>Cylon</i>, <i>Lion</i>.</li>
  <li><b>Variables</b> range over objects, e.g. the variable <i>c</i> could represent a city, <i>x</i> an integer, <i>s</i> a species. By convention, variables start with a lowercase character.</li>
  <li><b>Functions</b> are mappings between a list of objects to another object, e.g. <i>CapitalOf</i> could take a country and return a city, while <i>Multiply</i> takes two numbers and returns a number.</li>
</ol>

<p>Example:</p>

\[Add(x, 5).\]

<p><i>Add</i> is a function taking two numbers and returning a number, <i>x</i>
is a variable, and 5 is a constant. Since a function is a term, it can be used
within functions:</p>

\[Add(Multiply(x, y), 5).\]

<h2>Predicates</h2>

<p>First-order logic formulas ultimately resolve to a truth value: True or
False, yet the terms we've seen return objects. To get a truth value, we need
predicates. A predicate is like a function but it maps terms to a truth value
instead of mapping them to a term. For example, if we want to say that adding 0
to <i>x</i> yields <i>x</i>, we can write:</p>

\[Equals(Add(x, 0), x).\]

<p>It's common to use the equal sign for the "equals" (or identity) predicate:</p>

\[Add(x, 0) = x.\]

<p><i>Equals</i> is a predicate. In this case it takes two numbers and returns
true or false. We could have a predicate taking three cities and return
true if they are on the same continent:</p>

\[SameContinent(Toronto, c, CapitalOf(LargestCountryOf(Europe))),\]

<p>where <i>SameContinent</i> is a predicate, <i>Toronto</i> and <i>Europe</i>
are constants, <i>c</i> a variable ranging over cities, and both
<i>CapitalOf</i> and <i>LargestCountryOf</i> are functions taking a single
argument.</p>

<h2>Atomic sentences</h2>

<p>An atomic sentence is something that, alone, is a valid first-order logic formula. A predicate
is an atomic sentence since it returns a truth value, but we also have two special symbols: True and False.</p>

<p><b>True</b> is also called <i>top</i>, and can be represented with the symbol \(\top\).</p>

<p><b>False</b> is also called <i>bottom</i>, and can be represented with the symbol \(\bot\).</p>

<h2>Connectives</h2>

<p>You can connect sentences with connectives to form complex sentences. The
standard connectives are:</p>

<ol style='list-style-type: upper-roman'>
  <li>The binary connective <b>and</b>: \(x \land y\), which is true only if both \(x\) and \(y\) are true. Like all other connective shown here, if \(x\) and \(y\) are sentences, then \(x \land y\) is also a valid sentence.</li>
  <li>The binary connective <b>or</b>: \(x \lor y\), which is true only if \(x\) is true, if \(y\) is true, or if both are true.</li>
  <li>The binary connective <b>implies</b>: \(x \Rightarrow y\), returns true in all cases, except if \(x\) is true and \(y\) is false.</li>
  <li>The binary connective <b>iff</b>: \(x \iff y\), returns true if \(x\) and \(y\) have the same value, that is if they are both true, or both false.</li>
  <li>The binary connective <b>xor</b> (exclusive or): \(x \oplus y\), returns true if \(x\) and \(y\) have different values.</li>
  <li>The unary connective <b>not</b>: \(\lnot x\), which is true only if \(x\) is false.</li>
</ol>

<p>Be careful with implication, there is nothing wrong with it, except that it
doesn't fit how we use the term <i>implies</i>. For example:
\(Equals(AgeOf(Earth), 42) \Rightarrow StillAlive(Elvis)\) is true. If you're
confused, read again the description of <b>implies</b>.</p>

<h2>Qualifiers</h2>

<p>There are two qualifiers in first-order logic: the universal qualifier "for
all" denoted \(\forall\), and the existential qualifier "exists" denoted
\(\exists\)). They, well, qualify variables, e.g.:</p>

\[\forall x: Multiply(x, 0) = 0\]

<p>reads "for all x, multiplying x by 0 yields 0". Normally, all variables
should be qualified to determine their scope, e.g.:</p> 

\[\forall x \exists y: RealNumber(x) \Rightarrow GreaterThan(y, x)\]

<p>which means, "for all real numbers x, there is a number y that is greater
than x".</p>

<p>A last example: we can express "there is a color c brighter than x, unless x
is white" with:</p>

\[\forall x \exists c: IsWhite(x) \lor BrighterThan(c, x).\]



]]></summary>
</entry>
<entry>
    <title>Automated reasoning in F#, Scala, Haskell, C++, and Julia</title>
    <link href="http://phdp.github.io//posts/2015-04-05-automated-reasoning.html" />
    <id>http://phdp.github.io//posts/2015-04-05-automated-reasoning.html</id>
    <published>2015-04-05T00:00:00Z</published>
    <updated>2015-04-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Automated reasoning in F#, Scala, Haskell, C++, and Julia</h1>
<a href="https://twitter.com/share" class="twitter-share-button" data-text="Automated reasoning in F#, Scala, Haskell, C++, and Julia" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>2015.04.05</p>
<p>We need to simplify the following expression:</p>

\[e = (1 + 0 \times x) \times 3 + 12.\]

<p>Luckily for us, we won't have to remember any elementary school arithmetic,
because Harris' excellent <a
  href='http://www.cambridge.org/ca/academic/subjects/computer-science/programming-languages-and-applied-logic/handbook-practical-logic-and-automated-reasoning'>
  <i>Handbook of Practical Logic and Automated Reasoning</i></a> begins with a
simple algorithm to do exactly that. It's not complicated, but it's a pretty
good barometer of how painful a programming language will be for the kind of
hybrid (probabilistic logic, or statistical relational) approaches I work with.
Here, I compare the implementations of Harris' simple algorithm in F#, Scala,
Haskell, C++, and Julia.</p>

<p>No programming languages were hurt while writing this post. It's not a
competition, and I avoided talking about languages I dislike. Sum types are
discussed in length because they are awesome and useful for this problem
(and many, many others).</p>

<h2>The ML family</h2>

<p>Harris' book uses OCaml, a popular language for solvers. F#, Haskell, and
Scala all share roots with OCaml, with F# being the closest thing to an OCaml
dialect. I'll start with F#:</p>

<pre><code class="fsharp">/// A sum type for the expression.
/// An expression is either a var (which is a string), a constant
/// (which is an integer), an addition (made of two expressions)
/// or a multiplication (also made of two expressions).
type Expr =
    | Var of string
    | Const of int
    | Add of Expr * Expr
    | Mul of Expr * Expr

/// Simplify a single component of the expression. This function
/// takes an expression and use pattern matching to select the
/// right approach based on type and value. For example, if we
/// add a constant 0 to some x (which can be expression), then
/// we return x.
let simplify1 e =
    match e with
    | Add (Const 0, x)
    | Add (x, Const 0)
    | Mul (x, Const 1)
    | Mul (Const 1, x)        -> x
    | Mul (x, Const 0)
    | Mul (Const 0, x)        -> Const 0
    | Add (Const a, Const b)  -> Const (a + b)
    | Mul (Const a, Const b)  -> Const (a * b)
    | _                       -> e

/// Recursive function to simplify an entire expression.
let rec simplify e =
    match e with
    | Add (x, y) -> Add (simplify x, simplify y)
    | Mul (x, y) -> Mul (simplify x, simplify y)
    | _          -> e
    |> simplify1

/// Return the value string if the expression can be reduced to a constant.
let exprStr e =
    match e with
    | Const x -> string x
    | _       -> "The expression could not be simplified to a constant."

/// The |> operator sends the result on its left to its right, for example
/// "5.0 |> log |> sqrt" computes log(5.0) and then the square root of the
/// result. This is nice because it allows a more natural left-to-right
/// flow for functional programming.
[&lt;EntryPoint>]
let main argv =
    Add (Mul (Add (Const 1, Mul (Const 0, Var "x")), Const 3), Const 12)
    |> simplify
    |> exprStr
    |> printf "%s"
    0 /// F#'s main returns 0 for success à la C
</code></pre>

<p>It's almost the same as the OCaml version in Harris' book. The key trick is
to define an expression (Expr) as a variable (string) <b>or</b> a constant
(integer) <b>or</b> an addition <b>or</b> a multiplication (both made of two
expressions). The <b>or</b> is important, object-oriented programming languages
focuses on hierarchies of objects, while sum types define a type as a series of
alternatives. Sum types are important for another reason: they provide
an easy way to express things like "this function <i>might</i> return
an integer", for example in Haskell if we want a data structure that maps
keys to values:</p>

<pre><code class="haskell">import Data.Map (Map)
import qualified Data.Map as Map

capitals = Map.fromList [("Finland", "Helsinki"), ("France", "Paris"),
  ("Japan", "Tokyo"), ("South Korea", "Seoul"), ("Arrakis", "Arrakeen")]

lookupCapitals country = case Map.lookup country capitals of
  Just capital -> "The capital of " ++ country ++ " is " ++ capital ++ "."
  Nothing      -> "Is " ++ country ++ " even a country?"
</code></pre>

<p>The point is that a key-value store will only return a value if the key is
present. In this example, the map takes a country (string) and returns its
capital (string). However, when we try to take a value from the map with the
lookup function, Haskell returns a <b>Maybe</b> type with either <b>Just
String</b>, if the string provided is found in the map, or <b>Nothing</b> if
the key is absent. We then use pattern matching to deal with these
possibilities in the lookupCapitals function. One of the most common mistake in
programming is to return a null and not deal with it properly. The solution
with sum types is to return a wrapped value and handling possibilities
explicitly with pattern matching. It solves with types what many languages
would solve with exceptions and try-catch apparatuses.</p>

<pre><code class="haskell">ghci> lookupCapitals "Arrakis"
"The capital of Arrakis is Arrakeen."
ghci> lookupCapitals "Canada"
"Is Canada even a country?"</code></pre>

<p>Speaking of Haskell, the code for the algorithm is:</p>

<pre><code class="haskell">data Expr =
    Var String
  | Const Int
  | Add Expr Expr
  | Mult Expr Expr

simplify1 :: Expr -> Expr
simplify1 e = case e of
  Add (Const 0) x           -> x
  Add x (Const 0)           -> x
  Add (Const a) (Const b)   -> Const $ a + b
  Mult x (Const 0)          -> Const 0
  Mult (Const 0) x          -> Const 0
  Mult x (Const 1)          -> x
  Mult (Const 1) x          -> x
  Mult (Const a) (Const b)  -> Const $ a * b
  _                         -> e

simplify :: Expr -> Expr
simplify e = case e of
  Add x y   -> simplify1 $ Add (simplify x) (simplify y)
  Mult x y  -> simplify1 $ Mult (simplify x) (simplify y)
  _         -> simplify1 e

e = Add (Mult (Add (Const 1) (Mult (Const 0) (Var "x"))) (Const 3)) (Const 12)
s = simplify e

main = putStrLn $ case s of
  Const x -> show x
  _ -> "Could not simplify the expression to a constant."
</code></pre>

<p>It's quite similar to F#. I decided to add types explicitly to
<i>simplify1</i> and <i>simplify</i>, but Haskell is smart enough to deduce the
type without this. Arguably the only thing worth explaining is the $ operator.
The operator forces Haskell to evaluate the expression to the right of the
operator in priority, and if it reminds you of parentheses, you are absolutely
right. <i>x</i> and <i>y</i> have the same value here:</p>

<pre><code class="haskell">x = log (sqrt (exp 5.0))
y = log $ sqrt $ exp 5.0
</code></pre>

<p>The operator is there to reduce visual clutter. In my opinion, F# is easier
to read because the |> operator enforces left-to-right reading, which is more
natural than reading code inside-out:</p>

<pre><code class="fsharp">let z = exp 5.0 |> sqrt |> log</code></pre>

<p>Although it's trivial to simulate this operator in Haskell:</p>

<pre><code class="haskell">(|>) :: t0 -> (t0 -> t1) -> t1
(|>) x f = f x

-- Now valid Haskell:
z = exp 5.0 |> sqrt |> log</code></pre>

<p>And now for something a bit different: Scala. It's also a static
functional programming language with sum types, but its greater
integration with the object-oriented paradigm is evident:</p>

<pre><code class="scala">object Simplify {
  sealed abstract class Expr { override def toString = show(this) }
  case class Variable(name: String) extends Expr
  case class Const(value: Int) extends Expr
  case class Add(left: Expr, right: Expr) extends Expr
  case class Mult(left: Expr, right: Expr) extends Expr

  def evalOne(e: Expr): Expr = e match {
    case Add(Const(0), r)         => r
    case Add(l, Const(0))         => l
    case Add(Const(a), Const(b))  => Const(a + b)
    case Mult(Const(0), r)        => Const(0)
    case Mult(l, Const(0))        => Const(0)
    case Mult(Const(1), r)        => r
    case Mult(l, Const(1))        => l
    case Mult(Const(a), Const(b)) => Const(a * b)
    case _                        => e
  }

  def eval(e: Expr): Expr = e match {
    case Add(l, r)  => evalOne(Add(eval(l), eval(r)))
    case Mult(l, r) => evalOne(Mult(eval(l), eval(r)))
    case _          => e
  }

  def show(e: Expr) = e match {
    case Const(x) => print(x)
    case _        =>
      print("The expression could not be simplified to a constant.")
  }

  def main(args: Array[String]) {
    var e = Add(Mult(Add(Const(1), Mult(Const(0), Variable("x"))),
              Const(3)), Const(12))
    var s = eval(e)
    print(s)
  }
}
</code></pre>

<p>Everything is an object in Scala. Thus, we have to define the functions to
simplify as methods inside a singleton object. I named the functions
<i>evalOne</i> and <i>eval</i> since it has a bit odd to have a function named
<i>simplify</i> inside a Simplify object.</p>

<h2>C++</h2>

<p>Few understand every corner of C++'s monstrous standard. It's huge.  Surely,
with so many features, there must be something a quick way to solve this
problem in C++.  Well... no. It's a well-known lacuna with C++,
see <a href="https://parasol.tamu.edu/~yuriys/pm/"><i>Open and
Efficient Type Switch for C++</i></a> for a library built to implement
pattern matching (the effort is directed by the creator
of the C++ language). That said, here I'll use the boost library (A)
because solutions based only on the standard library are contrived and
(B) because boost is almost standard, and I don't want to rely on third-party
libraries.</p>

<pre><code class="cpp">#include &lt;iostream>
#include &lt;string>
#include &lt;boost/variant>

struct Add;
struct Mult;

using Expr = boost::variant<
  int,
  std::string,
  boost::recursive_wrapper&lt;Add>,
  boost::recursive_wrapper&lt;Mult>>;

struct Add {
  Expr left, right;
  Add(const Expr &left_, const Expr &right_) : left(left_), right(right_) {
  }
};

struct Mult {
  Expr left, right;
  Mult(const Expr &left_, const Expr &right_) : left(left_), right(right_) {
  }
};

struct add_visit : public boost::static_visitor&lt;Expr> {
  Expr operator()(int l, int r) const {
    return Expr(l + r);
  }
  template&lt;class X> Expr operator()(int l, const X &x) const {
    return l == 0? Expr(x) : Add(Expr(l), Expr(x));
  }
  template&lt;class X> Expr operator()(const X &x, int r) const {
    return r == 0? Expr(x) : Add(Expr(r), Expr(x));
  }
  template&lt;class X, class Y>
  Expr operator()(const X &x, const Y &y) const {
    return Add(Expr(x), Expr(y));
  }
};

struct mul_visit : public boost::static_visitor&lt;Expr> {
  Expr operator()(int l, int r) const {
    return Expr(l * r);
  }
  template&lt;class X> Expr operator()(int l, const X &x) const {
    return l == 0? Expr(0) : (l == 1? Expr(x) : Mult(Expr(l), Expr(x)));
  }
  template&lt;class X> Expr operator()(const X &x, int r) const {
    return r == 0? Expr(0) : (r == 1? Expr(x) : Mult(Expr(r), Expr(x)));
  }
  template&lt;class X, class Y>
  Expr operator()(const X &x, const Y &y) const {
    return Mult(Expr(x), Expr(y));
  }
};

struct simplify1 : public boost::static_visitor&lt;Expr> {
  Expr operator()(const Add &a) const {
    return boost::apply_visitor(add_visit(), a.left, a.right);
  }
  Expr operator()(const Mult &m) const {
    return boost::apply_visitor(mul_visit(), m.left, m.right);
  }
  template&lt;class X> Expr operator()(const X &x) const {
    return Expr(x);
  }
};

struct simplify : public boost::static_visitor&lt;Expr> {
  Expr operator()(const Add &a) const {
    auto left = boost::apply_visitor(simplify(), a.left);
    auto right = boost::apply_visitor(simplify(), a.right);
    auto add_lr = boost::apply_visitor(add_visit(), left, right);
    return boost::apply_visitor(simplify1(), add_lr);
  }
  Expr operator()(const Mult &m) const {
    auto left = boost::apply_visitor(simplify(), m.left);
    auto right = boost::apply_visitor(simplify(), m.right);
    auto mul_lr = boost::apply_visitor(mul_visit(), left, right);
    return boost::apply_visitor(simplify1(), mul_lr);
  }
  template&lt;class X> Expr operator()(const X &x) const {
    return x;
  }
};

struct print_expr : public boost::static_visitor&lt;std::string> {
  std::string operator()(int x) const { return std::to_string(x); };
  std::string operator()(const Expr &e) const {
    return "The expression could not be simplified to a constant.";
  };
};

int main() {
  auto e = Expr(Add(
      Expr(Mult(Expr(Add(Expr(1), Expr(Mult(Expr(0), Expr("x"))))),
      Expr(3))), Expr(12)));
  auto s = boost::apply_visitor(simplify(), e);
  std::cout << boost::apply_visitor(print_expr(), s) << std::endl;
  return 0;
}
</code></pre>

<p>This is boost::variant in action. My biggest qualm with this type of clever
header-heavy code is that you get to see a big chunk of the developers'
lifework unroll before your eyes every time a small mistake is made. If you
want to know how this code works, you need to read a bit on the visitor
pattern.</p>

<p>C++ template metaprogramming is both awesome and terrifying. Mostly
terrifying. Someone might find a simple way to use C++11/C++14 features to
build a small and nice matching library. <a
href='https://github.com/jbandela/simple_match'>This library</a> is halfway
there (with boost::variant, it might already allow matching on type but I have
yet to try). C++ is great for scientific computing, with tons of awesome
libraries, so I'd love to see a nice way to simulate pattern matching and sum
types.</p>

<h2>Julia</h2>

<p>Julia is an attempt to build a fast and flexible replacement for
R/Python/Matlab.  An issue with most dynamic languages is that there is no
elegant way to switch on type. To be fair, you cannot really do it with most
static languages either, see previous section... However, Julia supports
multiple-dispatch based on type annotation. To be clear, it's quite different
from the F#/Scala/Haskell approach.  In these languages, it is possible to define
sum types and do pattern matching on their constructors. With Julia, we define a
function with type annotation and let the interpreter dispatch based on runtime
type information. Multiple dispatch is supported in Julia for performance: it
allows the interpreter to compile optimized functions and use the best one,
adding predictability while keeping the language dynamic (for some reason...).
Here's the algorithm in Julia:</p>

<pre><code class="julia">abstract Expr

type Const <: Expr; val::Int end
type Var <: Expr; name::String end
type Add <: Expr; left::Expr; right::Expr end
type Mult <: Expr; left::Expr; right::Expr end

add(x::Const, y::Const) = Const(x.val + y.val)
add(x::Const, y::Expr) = x.val == 0? y : Add(x, y)
add(x::Expr, y::Const) = add(y, x)
add(x::Expr, y::Expr) = Add(x, y)

mult(x::Const, y::Const) = Const(x.val * y.val)
mult(x::Const, y::Expr) = x.val == 1? y : (x.val == 0? Const(0) : Mult(x, y))
mult(x::Expr, y::Const) = mult(y, x)
mult(x::Expr, y::Expr) = Mult(x, y)

simplify1(a::Add) = add(a.left, a.right)
simplify1(m::Mult) = mult(m.left, m.right)
simplify1(e::Expr) = e

simplify(a::Add) = simplify1(Add(simplify(a.left), simplify(a.right)))
simplify(m::Mult) = simplify1(Mult(simplify(m.left), simplify(m.right)))
simplify(e::Expr) = e

printExpr(c::Const) = print(c.val)
printExpr(e::Expr) =
  print("The expression could not be simplified to a constant.")

e = Add(Mult(Add(Const(1), Mult(Const(0), Var("x"))), Const(3)), Const(12))
s = simplify(e)
printExpr(s)
</code></pre>

<p>Unlike pattern matching, we can only dispatch on type, so we need an if
expression (the ? operator in Julia, just like C), or I could've used the match
macro, but it's overkill here. It's not too inelegant, and at first I thought
it was a good enough way to simulate sum types and pattern matching. It matters
to the Julia ecosystem because these features are very useful to build solvers,
logic and theorem proving systems, etc etc. Pretty nice for a technical 
computing platform. Unfortunately, while Julia does well with this simple example,
I think an oddity with the language would soon bite us: return type declarations
are not allowed, and yes, it <i>is</i> a big deal.</p>

<p>First, it's a question of correctness: you can return a float thinking
you're returning an integer. That's awful. Also, since annotation is not
allowed for the return value, it's also impossible to add annotation for a
higher-order function (a function taking functions as input). As a concrete
example, first-order logic has <i>predicates</i> mapping objects to a boolean,
and <i>functions</i> mapping objects to objects. We'd like to do:</p>

<pre><code class="julia">solve(pre::(Object -> Bool), ...)

solve(fun::(Object -> Object), ...)
</code></pre>

<p>But instead, we'd have to test the type of the return value inside the
function. That said, Julia is young and <a
href='https://github.com/JuliaLang/julia/issues/1090'>it might get return type
declarations at some point.</a></p>

<h2>Conclusion</h2>

<p>Sum types and pattern matching are awesome.</p>



]]></summary>
</entry>
<entry>
    <title>Knowledge representation and species interactions</title>
    <link href="http://phdp.github.io//posts/2014-06-11-food-webs.html" />
    <id>http://phdp.github.io//posts/2014-06-11-food-webs.html</id>
    <published>2014-06-11T00:00:00Z</published>
    <updated>2014-06-11T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Knowledge representation and species interactions</h1>
<a href="https://twitter.com/share" class="twitter-share-button" data-text="Knowledge representation and species interactions" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>2014.06.11</p>
<h2>The food web</h2>

<p>One of the most fascinating aspect of ecology is the complex web of
interactions between individuals (or populations, or species), and how it
shapes the structure of communities. But what is the best way to represent
these interactions?</p>

<p>The classical representation is a
directed network. <a href='http://mangal.uqar.ca/data/network/17/'>Here's
one from the mangal database</a> [2]. We can have predator-prey interactions,
parasitism, mutualism, competition, etc etc...</p>

<p>However, it's a somewhat limited representation. A good way to evaluate a
knowledge representation is to look at the possible queries. What questions
can be answered? What questions cannot be answered? How expressive can the
queries be? How expressive are the answers?</p>

<p>Despite their widespread use, these interactions networks can only answer
one question: is there a binary interaction between X and Y? The <i>binary
</i> part is important, because these networks cannot deal with indirect
relationships such as: X eats Y except when W is there.</p>

<p>It doesn't scale well either: two species might only interact in a given
region, a problem solved with distinct networks, but we would need distinct
networks for every region with distinct interactions and a lot of information
will be repeated.</p>

<h2>Going stochastic</h2>

<p>Instead of saying X eats Y, we could say X eats Y with probability Z.
Adopting a probabilistic perspective does solve quite a few issues. We can
now handle uncertainty and to some extent spatio-temporal variations. That
said, we still cannot handle indirect relationships, and it doesn't scale
that well.</p>

<p>For example, if species A and B compete on the west coast with probability
0.9 but only with probability 0.1 on the east coast, we would lose important
information by having a network say they compete with probability 0.5. Dividing
the network in two would improve our model's accuracy, but we are again getting
in the messy network-of-networks business.  </p>

<p>My supervisors, Timothée Poisot and Dominique Gravel, recently proposed a
metaweb concept that includes, among many other ideas, probabilistic links, but
in their case it's more than just adding probabilities to links [3].</p>

<h2>A unified path to unification</h2>

<p>To criticize an approach to ecology for missing some features is too easy.
All representations have limitations, and any approach to science relies on
some simplification of reality. However, in this case we can have our cake and
eat it too by looking at what is going on in the field of knowledge
representation (KR), which has been defined as [0]:</p>

<p><blockquote>[...] the scientific domain concerned with the study of
computational models able to explicitly represent knowledge by symbols and
to process these symbols in order to produce new ones representing other
pieces of knowledge. Systems built upon such computational models are called
knowledge-based systems. Their main components are a knowledge base and a
reasoning engine.</blockquote></p>

<p>To illustrate, let's look at two lizards: <i>P. cinereus</i> and <i>P.
hoffmani</i> [1]. The two species essentially hunt the same preys but, when
they are found in the same region, character displacement pushes them to
specialize on different preys. This fact cannot be easily express with
standard knowledge representations for food webs, but we can with a bit
of logic:</p>

\[presence(\mbox{cinereus}, r) \land presence(\mbox{hoffmani}, r) \Rightarrow eat(\mbox{cinereus}, A, r).\]

<p>The formula reads: the presence of cinereus in region \(r\) and the presence
of hoffmani in \(r\) implies that cinereus eats prey A in \(r\). Formulas like
this be seen as templates: presence(cinereus) will be either true or false at
any given place, but a probability is assigned to the entire formula so it can
be revised with new evidence [4]. This is an important point, it means we can
use the standard food webs as evidence to build these logical formulas, but we
still get a probabilistic model capable of handling uncertainty.</p>

<p>The formula is readable, can be used with modern inference tools, and is
very flexible, but there's better. What if the presence of cinereus in \(r\)
could be predicted with a few conditions, we could have something like
this:</p>

\[northAmerica(r) \land (presence(A, r) \lor presence(B, r)) \Rightarrow presence(\mbox{cinereus}, r).\]

<p>If the region \(r\) is in north America and if either species A or B are
present, then cinereus will be present. Again, this equation would be
assigned a probability. This is a simplistic model of presence/absence, but
the point is that this knowledge representation allows different formula to
be combined. Various evidence can be used together instead of having a wall
between ecological facts, and such database of probabilistic logical formula
supports sophisticated queries.</p>

<p>There are many discussions about having integrative frameworks and
theories in ecology. This is especially true for interaction networks, which
are often present in one form or another in ecology. Ironically, these
discussions of integration are often ignoring modern research in
other fields. Knowledge representation offers powerful tools with mature
software that are worth checking, especially if we want to understand
how different ideas and evidence can be combined.</p>

<h2>References</h2>

<p>[0] M Chein and M-L Mugnier. <i>Graph-based Knowledge Representation</i>. Springer, 2009.</p>

<p>[1] JB Losos. <a href='http://www.oeb.harvard.edu/faculty/losos/jblosos/pdfs/pnas.pdf'>Ecological character displacement and the study of adaptation</a>. PNAS, 2000.</p>

<p>[2] T Poisot, B Baiser, JA Dunne, S Kéfi, F Massol, N Mouquet, TN Romanuk, DB Stouffer, SA Wood, and D Gravel. <a href='http://dx.doi.org/10.1101/002634'>Mangal - making complex ecological network analysis simpler</a>. <i>bioRxiV</i>, 2014.</p>

<p>[3] T Poisot, DB Stouffer, and D Gravel. <a href='http://dx.doi.org/10.1101/001677'>Beyond species: why ecological interactions vary through space and time</a>. <i>bioRxiV</i>, 2014.</p>

<p>[4] M Richardson and P Domingos. Markov logic networks. <i>Machine Learning</i> <b>62</b> (1-2): 107–136, 2006.</p>


]]></summary>
</entry>
<entry>
    <title>Scriptoria.info - Tracking science manuscripts under revision control systems</title>
    <link href="http://phdp.github.io//posts/2013-07-22-scriptopia.html" />
    <id>http://phdp.github.io//posts/2013-07-22-scriptopia.html</id>
    <published>2013-07-22T00:00:00Z</published>
    <updated>2013-07-22T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Scriptoria.info - Tracking science manuscripts under revision control systems</h1>
<a href="https://twitter.com/share" class="twitter-share-button" data-text="Scriptoria.info - Tracking science manuscripts under revision control systems" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>2013.07.22</p>
<p><i><b>Update 2014-09-06</b>: I wanted Scriptoria to be a group effort,
something built by several scientists, especially since I never intended to
stay in academia after the Ph.D. I failed to create enough momentum around the
project, so I'm moving on...</i></p>

<p>There is widespread dissatisfaction with the way scientific publishing is
done, but fortunately many (cheaper) alternatives are emerging. Among these
alternatives is git (and revision control systems). Karthik Ram recently
wrote a piece on the use of git in science: <a href=
"http://www.scfbm.org/content/8/1/7/">http://www.scfbm.org/content/8/1/7/</a>.
Highly suggested reading.</p>

<p>The put it bluntly: revision control systems are more modern and
efficient than our peer-review system (my words, not his). With git and
github (a hosting service for git), <a href=
"https://github.com/PhDP/article_preprint/commits/master">changes are
tracked, with the full history of the document preserved in the repository
</a>. Collaborators can easily fork the repository of the manuscript, make
changes, and then push back the changes to a main repository.</p>

<p>Git was built to allow potentially thousands of developers to work on the
same code, create branches to test new ideas, and push back their changes
(if they want to merge everything into a single version). Better: websites
like <a href= "https://github.com/">GitHub</a>, <a href=
"https://bitbucket.org/">BitBucket</a>, <a href="https://code.google.com/">
Google Code</a>, Microsoft's <a href ="http://www.codeplex.com/">CodePlex</a>,
or <a href="http://gitorious.org/" >Gitorious</a> (itself an open source
project), allow the users to create open git repositories free of charge,
with wiki systems and bug tracking included.</p>

<p>Bug tracking is particularly great for science. Bug tracking systems are
essentially the software equivalent of asking a revision in a peer-review.
Found a problem with some paper? <a href=
"https://github.com/weecology/data-sharing-paper/issues/71"> Open a freaking
issue!</a> Open manuscripts and open reviews, all free, and all this thanks
to git, an open-source piece of software originally written for the Linux
kernel.</p>

<p>Git, and other similar systems, are potentially very disruptive and not
only for science, see <a href=
"http://www.ted.com/talks/clay_shirky_how_the_internet_will_one_day_transform_
government.html">Clay Shirky's great talk on the subject</a>. These systems
were built by software engineers with a great deal of experience on close
collaborations. Several scientists are already using git to write
manuscripts... the problem is, there is no way to search these manuscripts,
no way to know where they are.</p>

<p>Git et al. are decentralized and it's fine. Actually, I would rather not
have all scientific manuscripts at the same place. However, we need a tool
to track the manuscripts being developed on github, bitbucket, google code.
We need this tool both to browse these open manuscripts but also to create
incentives for scientists to push their manuscripts online as soon as
possible.</p>

<p>This is Scriptoria.info, a project to track manuscripts being written on
github, bitbucket, gitorious, and other hosting services git revision
control systems. The goal of Scriptoria is not to host repositories but
simply track them in the various hosting services, allow them to be search,
and offer a simple API. I see the project as a thin layer over an already
well-established system. Scriptoria is not ready (as of 2013.07.22), it's
just started! The code will be developed on <a href=
"https://github.com/PhDP/Scriptoria">github</a> and everyone is free to
contribute. <a href="https://twitter.com/recology_">Scott Chamberlain</a>
already suggested <a href= "https://github.com/PhDP/Scriptoria/issues/7">
(via an issue!)</a>
 a way to track the manuscripts...</p>


]]></summary>
</entry>
<entry>
    <title>Machine learning and deep transfer learning</title>
    <link href="http://phdp.github.io//posts/2013-07-05-dtl.html" />
    <id>http://phdp.github.io//posts/2013-07-05-dtl.html</id>
    <published>2013-07-05T00:00:00Z</published>
    <updated>2013-07-05T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Machine learning and deep transfer learning</h1>
<a href="https://twitter.com/share" class="twitter-share-button" data-text="Machine learning and deep transfer learning" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>2013.07.05</p>
<p>This short text explains the basic idea behind deep
transfer learning, an ambitious attempt to build machine learning algorithms
capable of exploiting prior knowledge. If you're looking for a technical
treatment, I highly suggest Mihalkova's <a href=
"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.119.241&rep=rep1&typ
e=pdf">Mapping and Revising Markov Logic Networks for Transfer Learning</a>,
one of the best algorithm for deep transfer. Also, I do not dwell on
the distinctions between deep and shallow transfer, and the various subtypes
of machine learning algorithms (supervised vs nonsupervised, online vs
batch): I want to provide a strategic overview of what deep transfer learning
is about and why it's important.</p>

<h2>The standard approach to machine learning</h2>

<p>Machine learning is straightforward: data is fed to an algorithm that
builds a model and, hopefully, generate good predictions:</p>

<div class="imagecenter">
  <img src="../images/ml-900.png" alt="Machine learning">
</div>

<p>The data can be pretty much anything from ecological data to movie
preferences. Machine learning algorithms can build effective models because
they are tailored for the input data. It is hard, if not impossible, to
build by hand the right mathematical model to solve complex problems such as
handwriting recognition, spam detection, language processing and many, many,
other problems where no simple equation can be found. In these cases, we
have to step back and, instead of focusing on building the model ourselves,
we design algorithms to do it in our place. That's the essence of machine
learning. This approach has been incredibly powerful to solve a wide array
of difficult problems in pretty much all fields of inquiry: it's the <a href=
"http://www.csee.wvu.edu/~gidoretto/courses/2011-fall-cp/reading/TheUnreasonable%20EffectivenessofData_IEEE_IS2009.pdf">
unreasonable effectiveness of data.</a></p>

<p>Building models this way is good, but it has a few problems. What can we
do when we have little data? If the situation has changed since we collected
our data, is our model still good? When we face a similar situation, can we
reuse our previous model or do we need to build a new one?</p>

<h2>Deep transfer learning algorithms</h2>

<p>Machine learning algorithms use a <i>Tabula rasa</i> approach: the
algorithms start with nothing and build the model only with the supplied
data. It's simple, but it's also inefficient. Deep transfer learning is
about transferring knowledge between different tasks. Instead of starting
from scratch, deep transfer algorithms can exploit accumulated knowledge to
learn faster (we also have good reasons to think deep transfer is a key
component to build reliable models, but that's a more complicated topic). It
looks like this:</p>

<div class="imagecenter">
  <img src="../images/ml-transfer-900.png" alt="Deep transfer learning">
</div>

<p>The algorithm, instead of simply reading the input data, will exploit
data from a large data-set of prior knowledge. This, in itself, is tricky.
The algorithm must make a judgment call: what is relevant to the present
subject, what can be used, and what should be discarded? Certainly, our
model for US presidential elections will be awful if we try, say, <a href=
"http://en.wikipedia.org/wiki/Redskins_Rule">to bring data from football
games</a>. So there are risks to deep transfer learning, but the benefits
are huge.</p>

<p>To make an analogy with human learning, imagine you need to learn to run.
Of course, running is very similar to walking so you won't start from zero.
You're able to see that running and walking are similar tasks and thus you
can transfer your knowledge of walking into running. It allows you to learn
much faster, and also yield interesting information on how the two tasks are
related to each other. If you need to learn Mandarin though, running and
walking won't serve you. It's a more general approach: a very conservative
deep transfer learning algorithm could choose to always reject prior
information and would build the model just as before.</p>

<p>Machine learning starts from 0. Big data is nice, but it would be
much nicer if we could build models with more than a tiny fraction of it.
Deep transfer is about determining what is relevant in previous data-sets
and use this information to design better models, and faster! My thesis
focuses on doing just that, using the complex heterogeneous data-sets
found in ecology.</p>


]]></summary>
</entry>
<entry>
    <title>The case for open preprints in biology</title>
    <link href="http://phdp.github.io//posts/2013-05-14-case-preprint.html" />
    <id>http://phdp.github.io//posts/2013-05-14-case-preprint.html</id>
    <published>2013-05-14T00:00:00Z</published>
    <updated>2013-05-14T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>The case for open preprints in biology</h1>
<a href="https://twitter.com/share" class="twitter-share-button" data-text="The case for open preprints in biology" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>2013.05.14</p>
  <p>Initiated by a <a href="http://jabberwocky.weecology.org/2012/07/18/esa-journals-do-not-allow-papers-with-preprints/">simple tweet</a>, 
  this collaboration on preprints in biology was ultimately accepted in PLOS Biology. The whole writing
  process was done on GitHub (<a href="https://github.com/PhDP/article_preprint">here's the repo</a>).</p>

  <h2>Reference</h2>

  <p><b>P Desjardins-Proulx</b>, EP White, JJ Adamson, K Ram, T Poisot, and D
Gravel. The case for open preprints in biology. <i>PLOS Biology</i> 11(5): e1001563, 2013.
<a href="http://www.plosbiology.org/article/info%3Adoi%2F10.1371%2Fjournal.pbio.1001563">[URL]</a>
</p>


]]></summary>
</entry>
<entry>
    <title>L'intuition des Intelligences Artificielles</title>
    <link href="http://phdp.github.io//posts/2013-04-29-intuition-ai.html" />
    <id>http://phdp.github.io//posts/2013-04-29-intuition-ai.html</id>
    <published>2013-04-29T00:00:00Z</published>
    <updated>2013-04-29T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>L'intuition des Intelligences Artificielles</h1>
<a href="https://twitter.com/share" class="twitter-share-button" data-text="L'intuition des Intelligences Artificielles" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>2013.04.29</p>
<p>En 1997, DeepBlue bat le champion d'échecs Garry Kasparov lors d'un match 
de 6 parties. Depuis, les ordinateurs règnent en maîtres incontestés des 
échecs. Pourtant, leur victoire est en quelque sorte décevante. C'est une 
victoire de la force brute. DeepBlue, un dinosaure comparé aux programmes 
modernes, pouvait évaluer 200 millions de positions par seconde alors que 
les joueurs d'échecs ne considèrent que quelques coups par tour. Il est 
clair que les ordinateurs nous surpassent, et ce depuis longtemps, pour 
résoudre des problèmes mathématiques qui demandent une série bien définie 
d'étapes. Par exemple, le calcul de n'importe quelle racine carrée est très 
simple. Il suffit de suivre rigoureusement un certain nombre d'opérations et 
voilà ! Simple pour un ordinateur mais pas pour nous. Les auteurs de 
science-fiction nous offrent souvent la caricature d'ordinateurs incapables 
de penser globalement, incapables d'intuition. Bref, des DeepBlue qui 
écrasent l'être humain avec leur force de calcul. C'est une erreur. Toutes 
les I.A. (Intelligence Artificielle) ne sont pas des DeepBlue et nous 
développons actuellement des programmes qui ont une intelligence très 
similaire à la nôtre. C'est une quête pour construire des I.A. capables de 
raisonner sur des questions complexes. C'est une quête pour programmer 
l'intuition.</p>

<p>À première vue, l'intelligence humaine semble complètement différente des 
ordinateurs. Ces derniers conservent la plupart des données dans les disques 
durs qu'on peut voir comme de gigantesques tables. Pour accéder à un élément 
(une mémoire), il suffit de connaître sa position qui est représentée par un 
nombre. Mauvais nombre, mauvaise mémoire. À l'inverse, la mémoire humaine 
est résiliente et associative. Si je vous demande le nom du très 
charismatique premier ministre du Québec qui a dirigé la province entre 2003 
et 2012, la plupart des gens seront capables de trouver la bonne réponse, 
même si « très charismatique » colle difficilement au personnage. Autre 
différence : la capacité de calculs (ou évaluation) de notre cerveau est 
largement supérieure à DeepBlue. L'acte de reconnaître un objet (ceci est un 
chat, ça c'est un arbre) est très difficile. Même le plus puissant 
ordinateur serait incapable de se déplacer en forêt tout en évaluant la 
position et la nature des objets, ce que nous faisons pourtant sans grands 
efforts. Notre cerveau est donc très doué pour certains types d'analyses, 
surtout celles qui demandent de regrouper plusieurs évidences. Les 
spécialistes de l'I.A. tentent depuis longtemps de créer des I.A. qui 
ressemblent à l'intelligence humaine. Et ils ont réussi. Les réseaux de 
neurones artificiels font partie de ces techniques. Tout comme le cerveau 
humain, ces réseaux ont une mémoire résiliente et associative. Ils sont 
capables de prendre en compte un grand nombre d'évidences et les relations 
complexes qui lient ces évidences.</p>

<p>L'I.A. prend énormément d'expansion mais elle n'a pas la forme que les 
gens imaginent. Google utilise déjà ces techniques pour son moteur de 
recherche, pour traduire des textes, adapter les publicités. Amazon, 
Microsoft, IBM, Fujitsu; pratiquement toutes les compagnies de haute 
technologie investissent de grandes sommes en I.A. et les succès se 
multiplient. Goeffrey Hinton est un des grands spécialistes des réseaux de 
neurones artificiels. Il s'en sert pour apprendre à des programmes à 
raisonner sur des tâches complexes. Par exemple, ces réseaux de neurones 
peuvent reconnaître les chiffres (1, 2, 3, 4, …) mieux qu'un être humain. Si 
vous croyez que c'est facile, demandez à un professeur de mathématiques. Les 
formes des chiffres varient énormément et certains, moi par exemple, ont 
développé une incroyable capacité à écrire des 4 qui ressemblent à des 9, ou 
des 7 qui ressemblent à des 1. Personne n'a jamais réussi à écrire à la main 
un programme capable de reconnaître les chiffres. Les réseaux de neurones 
d'Hinton sont capables d'apprendre à les reconnaître et ils le font comme 
les humains: on gave le réseau de chiffres en leur donnant la bonne réponse 
(ça, c'est un quatre, ça, c'est un un, etc) et il apprend un modèle (très 
complexe!) qui lui permet ensuite de déduire le chiffre à partir d'une 
forme. Hinton n'écrit pas un programme pour reconnaître les chiffres, il 
écrit un programme capable d'apprendre à reconnaître les chiffres. Mieux 
encore: en 2012, Hinton et son équipe participent à un concours du géant 
pharmaceutique Merk. L'objectif est de découvrir des molécules au potentiel 
pharmaceutique. Les équipes de scientifiques qui participent à ce concours 
sont des experts dans le domaine, certains y travaillent depuis des 
décennies. L'équipe de Hinton arrive, en retard, au concours et n'a aucune 
expérience dans le domaine. Pourtant, il gagne! Un réseau de neurones 
artificiels, à qui on a donné une large base de données, a réussi à 
apprendre comment flairer une bonne molécule mieux que les experts. Le choc 
fut assez grand pour mériter à l'équipe d'Hinton un article dans le 
prestigieux New York Times.</p>

<p>Il faudra encore attendre plusieurs années avant de voir des I.A. 
maîtriser toutes les subtilités du langage humain, une tâche où notre 
cerveau est exceptionnellement bien adapté. Pour bien des tâches complexes 
cependant, ils commencent déjà à développer une redoutable intuition.  
L'intuition est un concept difficile à définir. Très brièvement, on peut 
dire que c'est un raisonnement fondé sur un grand nombre d'évidences. Prises 
individuellement, ces évidences peuvent être faibles, mais en groupe elles 
forment un modèle solide. C'est exactement ce que les réseaux de neurones 
font: ils analysent de grandes bases de données et apprennent à lire les 
relations subtiles, tout comme les humains maîtrisent les subtilités de leur 
métier après des années d'expérience. Ceci inclut plusieurs tâches: 
comprendre les systèmes économiques, financiers, moléculaires, et... 
écologiques. C'est ce qui m'a amené à l'I.A. Je m'intéresse aux forces qui 
maintiennent la biodiversité. Ces forces sont multiples et complexes, 
tellement complexes que je doute qu'on puisse enfermer Mère Nature dans une 
simple équation. Les outils mathématiques traditionnels ont longtemps eu de 
la difficulté à analyser les sujets complexes. Les I.A., cependant, ont tout 
ce qu'il faut pour percer ces mystères, même s'il reste beaucoup de chemin à 
faire. Le problème, c'est qu'on comprend encore mal l'intelligence. Un peu 
comme les pionniers de l'aviation tentaient maladroitement d'imiter les 
ailes des oiseaux, nous bâtissons des I.A. en imitant le cerveau humain. Une 
meilleure science de l'information nous permettra de dépasser les limites du 
cerveau humain, mais les succès actuels de l'I.A. sont tout de même 
impressionnants. Il a fallu quelques milliards d'années pour que la vie sur 
terre mène à une intelligence comme la nôtre. Les I.A. n'ont pas 100 ans et 
ils révolutionnent déjà le monde de la technologie.</p>


]]></summary>
</entry>
<entry>
    <title>Evolution of a transposon in Daphnia hybrid genomes</title>
    <link href="http://phdp.github.io//posts/2013-02-06-transposon.html" />
    <id>http://phdp.github.io//posts/2013-02-06-transposon.html</id>
    <published>2013-02-06T00:00:00Z</published>
    <updated>2013-02-06T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>Evolution of a transposon in Daphnia hybrid genomes</h1>
<a href="https://twitter.com/share" class="twitter-share-button" data-text="Evolution of a transposon in Daphnia hybrid genomes" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>2013.02.06</p>
  <h2>Reference</h2>

  <p>R Vergilino, TA Elliott, <b>P Desjardins-Proulx</b>, TJ Crease and F
Dufresne. Evolution of a transposon in <i>Daphnia</i> hybrid genomes.
<i>Mobile DNA</i> 4:7, 2013.
<a href="http://dx.doi.org/10.1186/1759-8753-4-7">DOI: 10.1186/1759-8753-4-7.</a></p>


]]></summary>
</entry>
<entry>
    <title>The repeatability of niche and neutral communities</title>
    <link href="http://phdp.github.io//posts/2012-09-24-repeatability.html" />
    <id>http://phdp.github.io//posts/2012-09-24-repeatability.html</id>
    <published>2012-09-24T00:00:00Z</published>
    <updated>2012-09-24T00:00:00Z</updated>
    <summary type="html"><![CDATA[<h1>The repeatability of niche and neutral communities</h1>
<a href="https://twitter.com/share" class="twitter-share-button" data-text="The repeatability of niche and neutral communities" data-via="phdpqc">Tweet</a>
<p id="dt"><script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>2012.09.24</p>
  <h2>Reference</h2>

  <p>D Ai, <b>P Desjardins-Proulx</b>, C Chu, and G Wang. The influence of
immigration and dispersal limitation on the repeatability of niche and neutral
communities. <i>PLOS ONE</i> 7(9): e46164.  <a
href="http://dx.doi.org/10.1371/journal.pone.0046164">DOI:
10.1371/journal.pone.0046164</a>. <a href="files/ai_2012.pdf">[PDF]</a></p>


]]></summary>
</entry>

</feed>
